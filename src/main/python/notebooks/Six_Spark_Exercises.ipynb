{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook have solutions for the exercises mentioed @ https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"500mb\") \\\n",
    "    .appName(\"Exercise1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df = spark.read.parquet('file:///home/rameshbabug/Documents/Tutorials/Input/Datasets/DatasetToCompleteTheSixSparkExercises/products_parquet/')\n",
    "products_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- num_pieces_sold: string (nullable = true)\n",
      " |-- bill_raw_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df = spark.read.parquet('file:///home/rameshbabug/Documents/Tutorials/Input/Datasets/DatasetToCompleteTheSixSparkExercises/sales_parquet/')\n",
    "sales_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seller_id: string (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- daily_target: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sellers_df = spark.read.parquet('file:///home/rameshbabug/Documents/Tutorials/Input/Datasets/DatasetToCompleteTheSixSparkExercises/sellers_parquet/')\n",
    "sellers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         0|   product_0|   22|\n",
      "|         1|   product_1|   30|\n",
      "|         2|   product_2|   91|\n",
      "|         3|   product_3|   37|\n",
      "|         4|   product_4|  145|\n",
      "+----------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|       1|         0|        0|2020-07-10|             26|kyeibuumwlyhuwksx...|\n",
      "|       2|         0|        0|2020-07-08|             13|jfyuoyfkeyqkckwbu...|\n",
      "|       3|         0|        0|2020-07-05|             38|uyjihlzhzcswxcccx...|\n",
      "|       4|         0|        0|2020-07-05|             56|umnxvoqbdzpbwjqmz...|\n",
      "|       5|         0|        0|2020-07-05|             11|zmqexmaawmvdpqhih...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|     2500000|\n",
      "|        1|   seller_1|      257237|\n",
      "|        2|   seller_2|      754188|\n",
      "|        3|   seller_3|      310462|\n",
      "|        4|   seller_4|     1532808|\n",
      "|        5|   seller_5|     1199693|\n",
      "|        6|   seller_6|     1055915|\n",
      "|        7|   seller_7|     1946998|\n",
      "|        8|   seller_8|      547320|\n",
      "|        9|   seller_9|     1318051|\n",
      "+---------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.show(5)\n",
    "sales_df.show(5)\n",
    "sellers_df.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out how many orders, how many products and how many sellers are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000040"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Orders Count\n",
    "sales_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sellers Count\n",
    "sellers_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Products Count\n",
    "products_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many products have been sold at least once? Which is the product contained in more orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.createOrReplaceTempView('products')\n",
    "sales_df.createOrReplaceTempView('orders')\n",
    "sellers_df.createOrReplaceTempView('sellers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_products_sold_atleast_once = spark.sql('''\n",
    "select count(distinct product_id) no_of_products_sold_atleast_once from sales\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_products_sold_atleast_once.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_in_more_orders = spark.sql('''\n",
    "select max(product_in_more_orders) as product_in_more_orders from (\n",
    "select count(product_id) product_in_more_orders from orders group by product_id)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_in_more_orders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many distinct products have been sold in each day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_products_in_each_day = spark.sql('''\n",
    "select date, count(distinct product_id) distinct_products_in_each_day from orders group by date order by distinct_products_in_each_day desc\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_products_in_each_day.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"3gb\") \\\n",
    "    .appName(\"Exercise1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_revenue_of_orders = spark.sql('''\n",
    "select avg(p.price * o.num_pieces_sold) as avg_revenue_of_orders from orders o join products p on o.product_id = p.product_id\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_revenue_of_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"500mb\") \\\n",
    "    .appName(\"Exercise2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_revenue_of_orders = spark.sql('''\n",
    "select avg() from (\n",
    "select o. from sellers s join orders o join prodcts p group by s.seller_id\n",
    "\n",
    ")\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"3gb\") \\\n",
    "    .appName(\"Exercise1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_most_seeling = spark.sql('''\n",
    "select s.seller_id , p. product_id from products p join orders o join sellers s \n",
    "where p.product_id = o.product_id \n",
    "and   o.seller_id = s.seller_id \n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
